{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/MultiViewUNet-TAVI/blob/main/src/training/TAVI_CLF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dog0QDqLZ9BK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMZ0R33OZ9BM"
      },
      "source": [
        "# Fix GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m6ZOKIKnZ9BN",
        "outputId": "dedc3c0e-cff3-4879-a531-0bc3b62e379b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing G-Drive ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "print(\"Installing G-Drive ... \")\n",
        "os.system(\"pip install -U --no-cache-dir gdown --pre > /dev/null\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUknlYSgZ9BN"
      },
      "source": [
        "# Downoad Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HHocoGCGZ9BN",
        "outputId": "324d3441-7efc-4e0a-d6fd-766073105409",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "os.system('gdown \"1wYPkE9LbNKExhnNTj6Enr0AS_qb-Vthn\"')\n",
        "os.system('unzip -o \"TAVI_STRESS_CLF_PARALLEL_v3.zip\" > /dev/null')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csXULJ2qZ9BN"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0jR8MOu7Z9BO"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/Stress/\"\n",
        "train_X1 = np.load(DATA_DIR + \"train_X1.npy\")\n",
        "train_X2 = np.load(DATA_DIR + \"train_X2.npy\")\n",
        "train_X3 = np.load(DATA_DIR + \"train_X3.npy\")\n",
        "train_Y = np.load(DATA_DIR + \"train_y.npy\")\n",
        "test_X1 = np.load(DATA_DIR + \"test_X1.npy\")\n",
        "test_X2 = np.load(DATA_DIR + \"test_X2.npy\")\n",
        "test_X3 = np.load(DATA_DIR + \"test_X3.npy\")\n",
        "test_Y = np.load(DATA_DIR + \"test_y.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE0tqQXpZ9BO"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aCtsfGEGZ9BO"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 4\n",
        "INITIAL_LEARNING_RATE = 0.0001\n",
        "INITIAL_EPOCH = 300\n",
        "EPOCH_PATIENCE = 30\n",
        "FINE_TUNE_EPOCH = 0\n",
        "TOTAL_EPOCH = INITIAL_EPOCH + FINE_TUNE_EPOCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsPEexpeZ9BO"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1tJQeJRTZ9BO",
        "outputId": "a77bb9a6-dd2a-4079-b535-69205fc0445f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " resizing (Resizing)         (None, 224, 224, 3)          0         ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " resizing_1 (Resizing)       (None, 224, 224, 3)          0         ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " resizing_2 (Resizing)       (None, 224, 224, 3)          0         ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (  (None, 224, 224, 3)          0         ['resizing[0][0]']            \n",
            " SlicingOpLambda)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 224, 224, 3)          0         ['resizing_1[0][0]']          \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2  (None, 224, 224, 3)          0         ['resizing_2[0][0]']          \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.nn.bias_add (TFOpLambda  (None, 224, 224, 3)          0         ['tf.__operators__.getitem[0][\n",
            " )                                                                  0]']                          \n",
            "                                                                                                  \n",
            " tf.nn.bias_add_1 (TFOpLamb  (None, 224, 224, 3)          0         ['tf.__operators__.getitem_1[0\n",
            " da)                                                                ][0]']                        \n",
            "                                                                                                  \n",
            " tf.nn.bias_add_2 (TFOpLamb  (None, 224, 224, 3)          0         ['tf.__operators__.getitem_2[0\n",
            " da)                                                                ][0]']                        \n",
            "                                                                                                  \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)           2358771   ['tf.nn.bias_add[0][0]',      \n",
            "                                                          2          'tf.nn.bias_add_1[0][0]',    \n",
            "                                                                     'tf.nn.bias_add_2[0][0]']    \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 2048)                 0         ['resnet50[0][0]']            \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 2048)                 0         ['resnet50[1][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 2048)                 0         ['resnet50[2][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 6144)                 0         ['global_average_pooling2d[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'global_average_pooling2d_1[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'global_average_pooling2d_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 6144)                 0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  786560    ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    129       ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24374401 (92.98 MB)\n",
            "Trainable params: 786689 (3.00 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = []\n",
        "features = []\n",
        "\n",
        "base_model = tf.keras.applications.ResNet50(\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "for i in range(3):\n",
        "    inp = tf.keras.Input(shape=(256, 256, 3))\n",
        "    x = tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE)(inp)\n",
        "    x = tf.keras.applications.resnet.preprocess_input(x)\n",
        "    x = base_model(x, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    inputs.append(inp)\n",
        "    features.append(x)\n",
        "\n",
        "x = tf.keras.layers.concatenate(features)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGtoEygxZ9BP",
        "outputId": "8be77160-4cfb-4f17-f71a-d7bfe55fe04d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "108/108 [==============================] - 35s 105ms/step - loss: 1.1398 - accuracy: 0.5556 - val_loss: 0.6555 - val_accuracy: 0.6250\n",
            "Epoch 2/300\n",
            "108/108 [==============================] - 8s 71ms/step - loss: 0.7419 - accuracy: 0.5995 - val_loss: 0.6562 - val_accuracy: 0.5833\n",
            "Epoch 3/300\n",
            "108/108 [==============================] - 8s 77ms/step - loss: 0.6730 - accuracy: 0.6273 - val_loss: 0.6502 - val_accuracy: 0.6250\n",
            "Epoch 4/300\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.6589 - accuracy: 0.6597 - val_loss: 0.6491 - val_accuracy: 0.6042\n",
            "Epoch 5/300\n",
            "108/108 [==============================] - 9s 82ms/step - loss: 0.6512 - accuracy: 0.6481 - val_loss: 0.6547 - val_accuracy: 0.6250\n",
            "Epoch 6/300\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.6403 - accuracy: 0.6620 - val_loss: 0.6491 - val_accuracy: 0.6250\n",
            "Epoch 7/300\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.6195 - accuracy: 0.6782 - val_loss: 0.6461 - val_accuracy: 0.6250\n",
            "Epoch 8/300\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.6179 - accuracy: 0.6505 - val_loss: 0.6479 - val_accuracy: 0.6250\n",
            "Epoch 9/300\n",
            "108/108 [==============================] - 8s 72ms/step - loss: 0.6445 - accuracy: 0.6389 - val_loss: 0.6498 - val_accuracy: 0.6250\n",
            "Epoch 10/300\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.6069 - accuracy: 0.6736 - val_loss: 0.6438 - val_accuracy: 0.5938\n",
            "Epoch 11/300\n",
            "108/108 [==============================] - 8s 72ms/step - loss: 0.6209 - accuracy: 0.6551 - val_loss: 0.6502 - val_accuracy: 0.6250\n",
            "Epoch 12/300\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.6001 - accuracy: 0.6806 - val_loss: 0.6592 - val_accuracy: 0.6250\n",
            "Epoch 13/300\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.6055 - accuracy: 0.6690 - val_loss: 0.6304 - val_accuracy: 0.5833\n",
            "Epoch 14/300\n",
            "108/108 [==============================] - 8s 73ms/step - loss: 0.5963 - accuracy: 0.6736 - val_loss: 0.6489 - val_accuracy: 0.5938\n",
            "Epoch 15/300\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.5620 - accuracy: 0.6968 - val_loss: 0.6310 - val_accuracy: 0.6146\n",
            "Epoch 16/300\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.6217 - accuracy: 0.6852 - val_loss: 0.6428 - val_accuracy: 0.6146\n",
            "Epoch 17/300\n",
            "108/108 [==============================] - 8s 73ms/step - loss: 0.5607 - accuracy: 0.7083 - val_loss: 0.6394 - val_accuracy: 0.6250\n",
            "Epoch 18/300\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.5898 - accuracy: 0.7014 - val_loss: 0.6439 - val_accuracy: 0.6042\n",
            "Epoch 19/300\n",
            "108/108 [==============================] - 8s 75ms/step - loss: 0.5687 - accuracy: 0.6875 - val_loss: 0.6566 - val_accuracy: 0.6250\n",
            "Epoch 20/300\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.5547 - accuracy: 0.7106 - val_loss: 0.6330 - val_accuracy: 0.5938\n",
            "Epoch 21/300\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.5357 - accuracy: 0.7245 - val_loss: 0.6364 - val_accuracy: 0.5833\n",
            "Epoch 22/300\n",
            "108/108 [==============================] - 8s 76ms/step - loss: 0.5231 - accuracy: 0.7269 - val_loss: 0.6656 - val_accuracy: 0.6250\n",
            "Epoch 23/300\n",
            "108/108 [==============================] - 9s 87ms/step - loss: 0.5392 - accuracy: 0.7245 - val_loss: 0.6224 - val_accuracy: 0.6042\n",
            "Epoch 24/300\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.5270 - accuracy: 0.7269 - val_loss: 0.6283 - val_accuracy: 0.6042\n",
            "Epoch 25/300\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.5303 - accuracy: 0.7199 - val_loss: 0.6430 - val_accuracy: 0.5938\n",
            "Epoch 26/300\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.5003 - accuracy: 0.7292 - val_loss: 0.6522 - val_accuracy: 0.5833\n",
            "Epoch 27/300\n",
            "108/108 [==============================] - 9s 87ms/step - loss: 0.5140 - accuracy: 0.7407 - val_loss: 0.6212 - val_accuracy: 0.5625\n",
            "Epoch 28/300\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.5070 - accuracy: 0.7338 - val_loss: 0.6267 - val_accuracy: 0.5938\n",
            "Epoch 29/300\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.4760 - accuracy: 0.7778 - val_loss: 0.6497 - val_accuracy: 0.6146\n",
            "Epoch 30/300\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.5028 - accuracy: 0.7407 - val_loss: 0.6284 - val_accuracy: 0.5833\n",
            "Epoch 31/300\n",
            "108/108 [==============================] - 8s 75ms/step - loss: 0.4778 - accuracy: 0.7662 - val_loss: 0.6278 - val_accuracy: 0.6042\n",
            "Epoch 32/300\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.4805 - accuracy: 0.7407 - val_loss: 0.6333 - val_accuracy: 0.5938\n",
            "Epoch 33/300\n",
            "108/108 [==============================] - 8s 75ms/step - loss: 0.5011 - accuracy: 0.7431 - val_loss: 0.6488 - val_accuracy: 0.6146\n",
            "Epoch 34/300\n",
            "108/108 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.7477"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LEARNING_RATE),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    [train_X1, train_X2, train_X3],\n",
        "    train_Y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=INITIAL_EPOCH,\n",
        "    validation_data=([test_X1, test_X2, test_X3], test_Y),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\",\n",
        "            patience=EPOCH_PATIENCE,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-y02j2saaQPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "hhT3fHfugaGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=INITIAL_LEARNING_RATE/10),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_fine = model.fit(\n",
        "    [train_X1, train_X2, train_X3],\n",
        "    train_Y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=TOTAL_EPOCH,\n",
        "    initial_epoch=history.epoch[-1],\n",
        "    validation_data=([test_X1, test_X2, test_X3], test_Y),\n",
        "    # callbacks=[\n",
        "    #     tf.keras.callbacks.EarlyStopping(\n",
        "    #         monitor=\"val_loss\",\n",
        "    #         patience=EPOCH_PATIENCE,\n",
        "    #         restore_best_weights=True\n",
        "    #     )\n",
        "    # ]\n",
        ")"
      ],
      "metadata": {
        "id": "xdaDMZVigZ5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc += history_fine.history['accuracy']\n",
        "val_acc += history_fine.history['val_accuracy']\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylim([0.8, 1])\n",
        "plt.plot([INITIAL_EPOCH-1,INITIAL_EPOCH-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.plot([INITIAL_EPOCH-1,INITIAL_EPOCH-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ujT4Ie3ChO_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opMdfnMUZ9BP"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7H55E87Z9BP"
      },
      "outputs": [],
      "source": [
        "pred_y = model.predict([test_X1, test_X2, test_X3])\n",
        "pred_y = np.round(pred_y).astype(int).reshape(-1)\n",
        "test_y = test_Y.astype(int)\n",
        "\n",
        "print(classification_report(test_y, pred_y))\n",
        "\n",
        "cm = confusion_matrix(test_y, pred_y)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}