{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/MultiViewUNet-TAVI/blob/dev/src/training/TAVI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qGP76Soh7eo"
      },
      "source": [
        "# Runtime Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DxmV-3idh7eq"
      },
      "outputs": [],
      "source": [
        "LOCAL_MACHINE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_TCNqhSh7er",
        "outputId": "c55d64c5-08b7-4fea-85e7-5d46aaed2e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 27 11:39:50 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "else:\n",
        "    print(gpu_info)\n",
        "\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "    print('Not using a high-RAM runtime')\n",
        "else:\n",
        "    print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lBmQa9Rh7es"
      },
      "source": [
        "# Fix G-Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBNHcIMGh7es",
        "outputId": "9b779370-f6f2-41ad-cdab-fee16c608d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing G-Drive ... \n",
            "Install Pix2Pix\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not LOCAL_MACHINE:\n",
        "    print(\"Installing G-Drive ... \")\n",
        "    os.system(\"pip install -U --no-cache-dir gdown --pre > /dev/null\")\n",
        "    print(\"Install Pix2Pix\")\n",
        "    os.system(\"pip install git+https://github.com/tensorflow/examples.git\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfrLpMKph7et"
      },
      "source": [
        "# Mount G-Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9xbY2Ggh7et",
        "outputId": "5e925c4d-8c1f-4423-94e8-31a8356ec5ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "if not LOCAL_MACHINE:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lWGNCyCh7et"
      },
      "source": [
        "# Download and Extract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImKwSB_kh7et",
        "outputId": "fd86adb8-5a05-4002-8484-9aa4817fcbee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Dataset ... \n",
            "Extracting Dataset ... \n"
          ]
        }
      ],
      "source": [
        "if not LOCAL_MACHINE:\n",
        "    print(\"Downloading Dataset ... \")\n",
        "    os.system(\"gdown 1xBO079FPIeE7T5VVsFwc8QeZxAfS4J9O\")\n",
        "    print(\"Extracting Dataset ... \")\n",
        "    os.system('unzip -o \"TAVI_REG_r17.zip\" > /dev/null')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq1mCzROh7eu"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nClEc8uph7eu"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow_examples.models.pix2pix import pix2pix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqPlBIIPh7eu"
      },
      "source": [
        "# Problem Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "njUHcK7Xh7eu"
      },
      "outputs": [],
      "source": [
        "PROBLEM = \"Curvature_2_Pressure\"\n",
        "\n",
        "MODEL_NAME = \"MultiViewUNet\"\n",
        "DATASET_PATH = \"/content/Images/\"\n",
        "TRAIN_DIR = \"Train/\"\n",
        "TEST_DIR = \"Test/\"\n",
        "INPUT_DIR = PROBLEM.split(\"_2_\")[0]\n",
        "TARGET_DIR = PROBLEM.split(\"_2_\")[1]\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Research/TAVI/Models/\"\n",
        "PRED_PATH = \"/content/drive/MyDrive/Research/TAVI/Predictions/\"\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 1000\n",
        "VAL_SPLIT = 0.2\n",
        "LEARNING_RATE = 0.001\n",
        "N_EPOCHS = 300\n",
        "PATIENCE = 30\n",
        "DROPOUT = 0.5\n",
        "\n",
        "EXP_NAME = f\"{PROBLEM}_{MODEL_NAME}_DO_{DROPOUT}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfz3WJv1h7eu"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJM2NlWwh7eu"
      },
      "source": [
        "## Vanilla UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e1VqTrGrh7eu"
      },
      "outputs": [],
      "source": [
        "class UNet:\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: int,\n",
        "        n_channels: int = 3,\n",
        "        width: int = 32,\n",
        "        depth: int = 4,\n",
        "        kernel_size: int = 3,\n",
        "    ):\n",
        "        self.img_size = img_size\n",
        "        self.n_channels = n_channels\n",
        "        self.width = width\n",
        "        self.depth = depth\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    @staticmethod\n",
        "    def conv(x: tf.Tensor, filters: int, kernel_size: int) -> tf.Tensor:\n",
        "        for i in range(2):\n",
        "            x = tf.keras.layers.Conv2D(\n",
        "                filters=filters,\n",
        "                kernel_size=kernel_size,\n",
        "                strides=1,\n",
        "                padding=\"same\",\n",
        "                data_format=\"channels_last\",\n",
        "                dilation_rate=1,\n",
        "                groups=1,\n",
        "                activation=None,\n",
        "                use_bias=True,\n",
        "                kernel_initializer=\"glorot_uniform\",\n",
        "                bias_initializer=\"zeros\",\n",
        "            )(x)\n",
        "\n",
        "            x = tf.keras.layers.BatchNormalization()(x)\n",
        "            x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def deconv(x: tf.Tensor, filters: int) -> tf.Tensor:\n",
        "        x = tf.keras.layers.Conv2DTranspose(\n",
        "            filters=filters,\n",
        "            kernel_size=2,\n",
        "            strides=2,\n",
        "            padding=\"same\",\n",
        "            output_padding=None,\n",
        "            data_format=None,\n",
        "            dilation_rate=1,\n",
        "            activation=None,\n",
        "            use_bias=True,\n",
        "            kernel_initializer=\"glorot_uniform\",\n",
        "            bias_initializer=\"zeros\",\n",
        "        )(x)\n",
        "\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def output(x: tf.Tensor) -> tf.Tensor:\n",
        "        return tf.keras.layers.Conv2D(3, (1, 1), activation=\"sigmoid\")(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def pool(x: tf.Tensor, pool_size: int = 2) -> tf.Tensor:\n",
        "        return tf.keras.layers.MaxPool2D(pool_size)(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def dropout(x: tf.Tensor, amount: float = 0.5) -> tf.Tensor:\n",
        "        return tf.keras.layers.Dropout(amount)(x)\n",
        "\n",
        "    def __call__(self) -> tf.keras.Model:\n",
        "        inputs = tf.keras.layers.Input(\n",
        "            shape=(self.img_size, self.img_size, self.n_channels)\n",
        "        )\n",
        "\n",
        "        # scaled = tf.keras.layers.Rescaling(1./255.0, offset=0)(inputs)\n",
        "\n",
        "        # ------------------ Downsampling ---------------------\n",
        "        downsample_layers = []\n",
        "        downsample_layers.append(\n",
        "            self.conv(x=inputs, filters=self.width,\n",
        "                      kernel_size=self.kernel_size)\n",
        "        )\n",
        "        for i in range(1, self.depth):\n",
        "            dropout_amount = 0.2 if i == 1 else DROPOUT\n",
        "            filters = int((2**i) * self.width)\n",
        "            downsample_layers.append(\n",
        "                self.dropout(\n",
        "                    self.pool(\n",
        "                        self.conv(\n",
        "                            x=downsample_layers[i - 1],\n",
        "                            filters=filters,\n",
        "                            kernel_size=self.kernel_size,\n",
        "                        )\n",
        "                    ),\n",
        "                    amount=dropout_amount,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # ------------------- Features --------------------\n",
        "        n_features = int((2**self.depth) * self.width)\n",
        "        self.features = self.pool(\n",
        "            self.conv(\n",
        "                x=downsample_layers[-1],\n",
        "                filters=n_features,\n",
        "                kernel_size=self.kernel_size,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # ------------------- Upsampling --------------------\n",
        "        upsample_layers = []\n",
        "        upsample_layers.append(self.features)\n",
        "        for i in range(1, self.depth + 1):\n",
        "            filters = int((2 ** (self.depth - i)) * self.width)\n",
        "            upsample_layers.append(\n",
        "                self.conv(\n",
        "                    x=self.dropout(\n",
        "                        tf.keras.layers.concatenate(\n",
        "                            [\n",
        "                                downsample_layers[self.depth - i],\n",
        "                                self.deconv(\n",
        "                                    x=upsample_layers[i - 1], filters=filters),\n",
        "                            ]\n",
        "                        ),\n",
        "                        amount=0.2\n",
        "                    ),\n",
        "                    filters=filters,\n",
        "                    kernel_size=self.kernel_size,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # ---------------------- Output -----------------------\n",
        "        outputs = self.output(upsample_layers[-1])\n",
        "\n",
        "        return tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDBA0xvgwjUb"
      },
      "source": [
        "# UNet - MobileNetv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyoeknw1wizE",
        "outputId": "e6bde485-2c8b-444e-915c-f97b3f93a012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=[IMG_SIZE, IMG_SIZE, 3], include_top=False\n",
        ")\n",
        "\n",
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "    \"block_1_expand_relu\",  # 112x112\n",
        "    \"block_3_expand_relu\",  # 56x56\n",
        "    \"block_6_expand_relu\",  # 28x28\n",
        "    \"block_13_expand_relu\",  # 14x14\n",
        "    \"block_16_project\",  # 7x7\n",
        "]\n",
        "base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
        "\n",
        "down_stack.trainable = True\n",
        "\n",
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),  # 32x32 -> 64x64\n",
        "]\n",
        "\n",
        "\n",
        "def unet_model(output_channels: int = 3):\n",
        "    inputs = tf.keras.layers.Input(shape=[IMG_SIZE, IMG_SIZE, 3])\n",
        "\n",
        "    # Downsampling through the model\n",
        "    skips = down_stack(inputs)\n",
        "    x = skips[-1]\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        concat = tf.keras.layers.Concatenate()\n",
        "        x = concat([x, skip])\n",
        "\n",
        "    # This is the last layer of the model\n",
        "    last = tf.keras.layers.Conv2DTranspose(\n",
        "        filters=output_channels,\n",
        "        kernel_size=3,\n",
        "        strides=2,\n",
        "        padding=\"same\",\n",
        "        activation=\"sigmoid\",\n",
        "    )  # 64x64 -> 128x128\n",
        "\n",
        "    x = last(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demEopCeh7ev"
      },
      "source": [
        "# Loss Functions / Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9-ke3H-6h7ev"
      },
      "outputs": [],
      "source": [
        "def attention_mse(y_true, y_pred):\n",
        "    _y_true = y_true[y_true != 1.0]\n",
        "    _y_pred = y_pred[y_true != 1.0]\n",
        "    squared_difference = tf.square(_y_true - _y_pred)\n",
        "    return tf.reduce_mean(squared_difference, axis=-1)\n",
        "\n",
        "\n",
        "def attention_mae(y_true, y_pred):\n",
        "    _y_true = y_true[y_true != 1.0]\n",
        "    _y_pred = y_pred[y_true != 1.0]\n",
        "    squared_difference = tf.abs(_y_true - _y_pred)\n",
        "    return tf.reduce_mean(squared_difference, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS70cKevh7ev"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1nL0lVRSh7ev"
      },
      "outputs": [],
      "source": [
        "def load_data_from_dir(path: str) -> tf.data.Dataset:\n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        directory=path,\n",
        "        labels=None,\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=BATCH_SIZE,\n",
        "        image_size=(IMG_SIZE, IMG_SIZE),\n",
        "        shuffle=False,\n",
        "        seed=42,\n",
        "        interpolation=\"bilinear\",\n",
        "        follow_links=False,\n",
        "        crop_to_aspect_ratio=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUnFP3mFh7ev"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M40uLH5mh7ev",
        "outputId": "2627bdb3-e301-45f9-aec5-c580b34bd7f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 432 files belonging to 1 classes.\n",
            "Found 432 files belonging to 1 classes.\n",
            "Found 96 files belonging to 1 classes.\n",
            "Found 96 files belonging to 1 classes.\n",
            "(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None))\n",
            "(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None))\n"
          ]
        }
      ],
      "source": [
        "trainX = load_data_from_dir(os.path.join(DATASET_PATH, TRAIN_DIR, INPUT_DIR))\n",
        "trainY = load_data_from_dir(os.path.join(DATASET_PATH, TRAIN_DIR, TARGET_DIR))\n",
        "testX = load_data_from_dir(os.path.join(DATASET_PATH, TEST_DIR, INPUT_DIR))\n",
        "testY = load_data_from_dir(os.path.join(DATASET_PATH, TEST_DIR, TARGET_DIR))\n",
        "\n",
        "train_ds = tf.data.Dataset.zip((trainX, trainY))\n",
        "test_ds = tf.data.Dataset.zip((testX, testY))\n",
        "\n",
        "print(train_ds.element_spec)\n",
        "print(test_ds.element_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syHL14qrh7ev"
      },
      "source": [
        "# Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F3FQHVSih7ew"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
        "train_ds = train_ds.map(lambda x, y: (\n",
        "    normalization_layer(x), normalization_layer(y)))\n",
        "test_ds = test_ds.map(lambda x, y: (\n",
        "    normalization_layer(x), normalization_layer(y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tz4Gni1h7ew"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "T0ftWoxzh7ew"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_batches = train_ds.cache().shuffle(\n",
        "    BUFFER_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "test_batches = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VizdFzJFh7ew"
      },
      "source": [
        "# Training Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KsEiuUyIh7ew"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join(MODEL_PATH, EXP_NAME)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        model_path,\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    ),\n",
        "]\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "model = UNet(IMG_SIZE)()\n",
        "# model = unet_model()\n",
        "\n",
        "model.compile(loss=attention_mse, optimizer=optimizer, metrics=[attention_mae])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJN5uRXih7ew"
      },
      "source": [
        "# Load Saved Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ncDyEeavh7ew"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     model.load_weights(model_path)\n",
        "# except:\n",
        "#     print(\"Checkpoint not found\")\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNG5F76Dh7ew"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmJMzj-Yh7ew",
        "outputId": "6a830d56-f8d1-4841-dc6e-06d276ae1540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0252 - attention_mae: 0.1095\n",
            "Epoch 1: val_loss improved from inf to 0.09143, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 58s 438ms/step - loss: 0.0252 - attention_mae: 0.1095 - val_loss: 0.0914 - val_attention_mae: 0.2517\n",
            "Epoch 2/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0117 - attention_mae: 0.0685\n",
            "Epoch 2: val_loss improved from 0.09143 to 0.09000, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 271ms/step - loss: 0.0117 - attention_mae: 0.0685 - val_loss: 0.0900 - val_attention_mae: 0.2278\n",
            "Epoch 3/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0102 - attention_mae: 0.0592\n",
            "Epoch 3: val_loss improved from 0.09000 to 0.05138, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 295ms/step - loss: 0.0102 - attention_mae: 0.0592 - val_loss: 0.0514 - val_attention_mae: 0.1757\n",
            "Epoch 4/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0096 - attention_mae: 0.0574\n",
            "Epoch 4: val_loss improved from 0.05138 to 0.04222, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 273ms/step - loss: 0.0096 - attention_mae: 0.0574 - val_loss: 0.0422 - val_attention_mae: 0.1540\n",
            "Epoch 5/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0091 - attention_mae: 0.0529\n",
            "Epoch 5: val_loss improved from 0.04222 to 0.03982, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 274ms/step - loss: 0.0091 - attention_mae: 0.0529 - val_loss: 0.0398 - val_attention_mae: 0.1450\n",
            "Epoch 6/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0086 - attention_mae: 0.0532\n",
            "Epoch 6: val_loss did not improve from 0.03982\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0086 - attention_mae: 0.0532 - val_loss: 0.0459 - val_attention_mae: 0.1571\n",
            "Epoch 7/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0080 - attention_mae: 0.0484\n",
            "Epoch 7: val_loss improved from 0.03982 to 0.03466, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 276ms/step - loss: 0.0080 - attention_mae: 0.0484 - val_loss: 0.0347 - val_attention_mae: 0.1317\n",
            "Epoch 8/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0081 - attention_mae: 0.0505\n",
            "Epoch 8: val_loss improved from 0.03466 to 0.03362, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 272ms/step - loss: 0.0081 - attention_mae: 0.0505 - val_loss: 0.0336 - val_attention_mae: 0.1289\n",
            "Epoch 9/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0077 - attention_mae: 0.0469\n",
            "Epoch 9: val_loss did not improve from 0.03362\n",
            "27/27 [==============================] - 7s 254ms/step - loss: 0.0077 - attention_mae: 0.0469 - val_loss: 0.0345 - val_attention_mae: 0.1303\n",
            "Epoch 10/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0075 - attention_mae: 0.0458\n",
            "Epoch 10: val_loss improved from 0.03362 to 0.03147, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 295ms/step - loss: 0.0075 - attention_mae: 0.0458 - val_loss: 0.0315 - val_attention_mae: 0.1222\n",
            "Epoch 11/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0073 - attention_mae: 0.0451\n",
            "Epoch 11: val_loss improved from 0.03147 to 0.02683, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 270ms/step - loss: 0.0073 - attention_mae: 0.0451 - val_loss: 0.0268 - val_attention_mae: 0.1109\n",
            "Epoch 12/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0070 - attention_mae: 0.0441\n",
            "Epoch 12: val_loss did not improve from 0.02683\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0070 - attention_mae: 0.0441 - val_loss: 0.0272 - val_attention_mae: 0.1109\n",
            "Epoch 13/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0070 - attention_mae: 0.0439\n",
            "Epoch 13: val_loss improved from 0.02683 to 0.02202, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 277ms/step - loss: 0.0070 - attention_mae: 0.0439 - val_loss: 0.0220 - val_attention_mae: 0.0952\n",
            "Epoch 14/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0069 - attention_mae: 0.0429\n",
            "Epoch 14: val_loss improved from 0.02202 to 0.01567, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 280ms/step - loss: 0.0069 - attention_mae: 0.0429 - val_loss: 0.0157 - val_attention_mae: 0.0803\n",
            "Epoch 15/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0067 - attention_mae: 0.0425\n",
            "Epoch 15: val_loss did not improve from 0.01567\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0067 - attention_mae: 0.0425 - val_loss: 0.0174 - val_attention_mae: 0.0803\n",
            "Epoch 16/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0065 - attention_mae: 0.0414\n",
            "Epoch 16: val_loss improved from 0.01567 to 0.01306, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 272ms/step - loss: 0.0065 - attention_mae: 0.0414 - val_loss: 0.0131 - val_attention_mae: 0.0680\n",
            "Epoch 17/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0065 - attention_mae: 0.0413\n",
            "Epoch 17: val_loss improved from 0.01306 to 0.00972, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 292ms/step - loss: 0.0065 - attention_mae: 0.0413 - val_loss: 0.0097 - val_attention_mae: 0.0563\n",
            "Epoch 18/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0066 - attention_mae: 0.0420\n",
            "Epoch 18: val_loss did not improve from 0.00972\n",
            "27/27 [==============================] - 7s 246ms/step - loss: 0.0066 - attention_mae: 0.0420 - val_loss: 0.0100 - val_attention_mae: 0.0587\n",
            "Epoch 19/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0064 - attention_mae: 0.0406\n",
            "Epoch 19: val_loss improved from 0.00972 to 0.00843, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 281ms/step - loss: 0.0064 - attention_mae: 0.0406 - val_loss: 0.0084 - val_attention_mae: 0.0490\n",
            "Epoch 20/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0063 - attention_mae: 0.0397\n",
            "Epoch 20: val_loss did not improve from 0.00843\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0063 - attention_mae: 0.0397 - val_loss: 0.0085 - val_attention_mae: 0.0490\n",
            "Epoch 21/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0061 - attention_mae: 0.0393\n",
            "Epoch 21: val_loss did not improve from 0.00843\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0061 - attention_mae: 0.0393 - val_loss: 0.0091 - val_attention_mae: 0.0514\n",
            "Epoch 22/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0062 - attention_mae: 0.0394\n",
            "Epoch 22: val_loss improved from 0.00843 to 0.00834, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 288ms/step - loss: 0.0062 - attention_mae: 0.0394 - val_loss: 0.0083 - val_attention_mae: 0.0467\n",
            "Epoch 23/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0060 - attention_mae: 0.0384\n",
            "Epoch 23: val_loss improved from 0.00834 to 0.00717, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 274ms/step - loss: 0.0060 - attention_mae: 0.0384 - val_loss: 0.0072 - val_attention_mae: 0.0410\n",
            "Epoch 24/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0059 - attention_mae: 0.0375\n",
            "Epoch 24: val_loss improved from 0.00717 to 0.00579, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 275ms/step - loss: 0.0059 - attention_mae: 0.0375 - val_loss: 0.0058 - val_attention_mae: 0.0339\n",
            "Epoch 25/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0058 - attention_mae: 0.0371\n",
            "Epoch 25: val_loss did not improve from 0.00579\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0058 - attention_mae: 0.0371 - val_loss: 0.0059 - val_attention_mae: 0.0366\n",
            "Epoch 26/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0057 - attention_mae: 0.0368\n",
            "Epoch 26: val_loss did not improve from 0.00579\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0057 - attention_mae: 0.0368 - val_loss: 0.0059 - val_attention_mae: 0.0350\n",
            "Epoch 27/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0056 - attention_mae: 0.0356\n",
            "Epoch 27: val_loss did not improve from 0.00579\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0056 - attention_mae: 0.0356 - val_loss: 0.0059 - val_attention_mae: 0.0351\n",
            "Epoch 28/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0056 - attention_mae: 0.0359\n",
            "Epoch 28: val_loss improved from 0.00579 to 0.00574, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 288ms/step - loss: 0.0056 - attention_mae: 0.0359 - val_loss: 0.0057 - val_attention_mae: 0.0323\n",
            "Epoch 29/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0056 - attention_mae: 0.0354\n",
            "Epoch 29: val_loss did not improve from 0.00574\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0056 - attention_mae: 0.0354 - val_loss: 0.0072 - val_attention_mae: 0.0334\n",
            "Epoch 30/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0057 - attention_mae: 0.0366\n",
            "Epoch 30: val_loss did not improve from 0.00574\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0057 - attention_mae: 0.0366 - val_loss: 0.0058 - val_attention_mae: 0.0323\n",
            "Epoch 31/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0055 - attention_mae: 0.0350\n",
            "Epoch 31: val_loss improved from 0.00574 to 0.00556, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 272ms/step - loss: 0.0055 - attention_mae: 0.0350 - val_loss: 0.0056 - val_attention_mae: 0.0315\n",
            "Epoch 32/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0054 - attention_mae: 0.0344\n",
            "Epoch 32: val_loss did not improve from 0.00556\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0054 - attention_mae: 0.0344 - val_loss: 0.0059 - val_attention_mae: 0.0318\n",
            "Epoch 33/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0054 - attention_mae: 0.0344\n",
            "Epoch 33: val_loss improved from 0.00556 to 0.00551, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 287ms/step - loss: 0.0054 - attention_mae: 0.0344 - val_loss: 0.0055 - val_attention_mae: 0.0300\n",
            "Epoch 34/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0053 - attention_mae: 0.0335\n",
            "Epoch 34: val_loss improved from 0.00551 to 0.00539, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 283ms/step - loss: 0.0053 - attention_mae: 0.0335 - val_loss: 0.0054 - val_attention_mae: 0.0287\n",
            "Epoch 35/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0053 - attention_mae: 0.0339\n",
            "Epoch 35: val_loss improved from 0.00539 to 0.00533, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 277ms/step - loss: 0.0053 - attention_mae: 0.0339 - val_loss: 0.0053 - val_attention_mae: 0.0301\n",
            "Epoch 36/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0052 - attention_mae: 0.0333\n",
            "Epoch 36: val_loss did not improve from 0.00533\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.0052 - attention_mae: 0.0333 - val_loss: 0.0058 - val_attention_mae: 0.0353\n",
            "Epoch 37/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0051 - attention_mae: 0.0322\n",
            "Epoch 37: val_loss did not improve from 0.00533\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0051 - attention_mae: 0.0322 - val_loss: 0.0061 - val_attention_mae: 0.0363\n",
            "Epoch 38/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0052 - attention_mae: 0.0331\n",
            "Epoch 38: val_loss improved from 0.00533 to 0.00523, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 287ms/step - loss: 0.0052 - attention_mae: 0.0331 - val_loss: 0.0052 - val_attention_mae: 0.0298\n",
            "Epoch 39/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0051 - attention_mae: 0.0327\n",
            "Epoch 39: val_loss did not improve from 0.00523\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0051 - attention_mae: 0.0327 - val_loss: 0.0058 - val_attention_mae: 0.0359\n",
            "Epoch 40/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0049 - attention_mae: 0.0314\n",
            "Epoch 40: val_loss did not improve from 0.00523\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0049 - attention_mae: 0.0314 - val_loss: 0.0057 - val_attention_mae: 0.0357\n",
            "Epoch 41/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0050 - attention_mae: 0.0321\n",
            "Epoch 41: val_loss improved from 0.00523 to 0.00514, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 272ms/step - loss: 0.0050 - attention_mae: 0.0321 - val_loss: 0.0051 - val_attention_mae: 0.0298\n",
            "Epoch 42/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0049 - attention_mae: 0.0315\n",
            "Epoch 42: val_loss improved from 0.00514 to 0.00505, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 292ms/step - loss: 0.0049 - attention_mae: 0.0315 - val_loss: 0.0050 - val_attention_mae: 0.0290\n",
            "Epoch 43/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0048 - attention_mae: 0.0313\n",
            "Epoch 43: val_loss did not improve from 0.00505\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0048 - attention_mae: 0.0313 - val_loss: 0.0055 - val_attention_mae: 0.0332\n",
            "Epoch 44/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0049 - attention_mae: 0.0313\n",
            "Epoch 44: val_loss did not improve from 0.00505\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0049 - attention_mae: 0.0313 - val_loss: 0.0057 - val_attention_mae: 0.0324\n",
            "Epoch 45/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0050 - attention_mae: 0.0315\n",
            "Epoch 45: val_loss did not improve from 0.00505\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0050 - attention_mae: 0.0315 - val_loss: 0.0054 - val_attention_mae: 0.0275\n",
            "Epoch 46/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0048 - attention_mae: 0.0312\n",
            "Epoch 46: val_loss did not improve from 0.00505\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0048 - attention_mae: 0.0312 - val_loss: 0.0051 - val_attention_mae: 0.0284\n",
            "Epoch 47/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0048 - attention_mae: 0.0312\n",
            "Epoch 47: val_loss did not improve from 0.00505\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0048 - attention_mae: 0.0312 - val_loss: 0.0051 - val_attention_mae: 0.0307\n",
            "Epoch 48/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0047 - attention_mae: 0.0301\n",
            "Epoch 48: val_loss did not improve from 0.00505\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.0047 - attention_mae: 0.0301 - val_loss: 0.0053 - val_attention_mae: 0.0301\n",
            "Epoch 49/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0049 - attention_mae: 0.0314\n",
            "Epoch 49: val_loss did not improve from 0.00505\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0049 - attention_mae: 0.0314 - val_loss: 0.0059 - val_attention_mae: 0.0294\n",
            "Epoch 50/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0048 - attention_mae: 0.0307\n",
            "Epoch 50: val_loss improved from 0.00505 to 0.00492, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 280ms/step - loss: 0.0048 - attention_mae: 0.0307 - val_loss: 0.0049 - val_attention_mae: 0.0270\n",
            "Epoch 51/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0046 - attention_mae: 0.0297\n",
            "Epoch 51: val_loss did not improve from 0.00492\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0046 - attention_mae: 0.0297 - val_loss: 0.0050 - val_attention_mae: 0.0290\n",
            "Epoch 52/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0045 - attention_mae: 0.0292\n",
            "Epoch 52: val_loss improved from 0.00492 to 0.00492, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 284ms/step - loss: 0.0045 - attention_mae: 0.0292 - val_loss: 0.0049 - val_attention_mae: 0.0278\n",
            "Epoch 53/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0045 - attention_mae: 0.0291\n",
            "Epoch 53: val_loss did not improve from 0.00492\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0045 - attention_mae: 0.0291 - val_loss: 0.0050 - val_attention_mae: 0.0290\n",
            "Epoch 54/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0044 - attention_mae: 0.0288\n",
            "Epoch 54: val_loss did not improve from 0.00492\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0044 - attention_mae: 0.0288 - val_loss: 0.0053 - val_attention_mae: 0.0309\n",
            "Epoch 55/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0044 - attention_mae: 0.0285\n",
            "Epoch 55: val_loss did not improve from 0.00492\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0044 - attention_mae: 0.0285 - val_loss: 0.0062 - val_attention_mae: 0.0362\n",
            "Epoch 56/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0044 - attention_mae: 0.0286\n",
            "Epoch 56: val_loss did not improve from 0.00492\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0044 - attention_mae: 0.0286 - val_loss: 0.0051 - val_attention_mae: 0.0298\n",
            "Epoch 57/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0043 - attention_mae: 0.0281\n",
            "Epoch 57: val_loss did not improve from 0.00492\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0043 - attention_mae: 0.0281 - val_loss: 0.0072 - val_attention_mae: 0.0414\n",
            "Epoch 58/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0043 - attention_mae: 0.0279\n",
            "Epoch 58: val_loss improved from 0.00492 to 0.00487, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 287ms/step - loss: 0.0043 - attention_mae: 0.0279 - val_loss: 0.0049 - val_attention_mae: 0.0275\n",
            "Epoch 59/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0043 - attention_mae: 0.0282\n",
            "Epoch 59: val_loss did not improve from 0.00487\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0043 - attention_mae: 0.0282 - val_loss: 0.0051 - val_attention_mae: 0.0298\n",
            "Epoch 60/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0043 - attention_mae: 0.0283\n",
            "Epoch 60: val_loss did not improve from 0.00487\n",
            "27/27 [==============================] - 7s 253ms/step - loss: 0.0043 - attention_mae: 0.0283 - val_loss: 0.0049 - val_attention_mae: 0.0263\n",
            "Epoch 61/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0042 - attention_mae: 0.0274\n",
            "Epoch 61: val_loss did not improve from 0.00487\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0042 - attention_mae: 0.0274 - val_loss: 0.0049 - val_attention_mae: 0.0278\n",
            "Epoch 62/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0041 - attention_mae: 0.0270\n",
            "Epoch 62: val_loss improved from 0.00487 to 0.00480, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 288ms/step - loss: 0.0041 - attention_mae: 0.0270 - val_loss: 0.0048 - val_attention_mae: 0.0262\n",
            "Epoch 63/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0042 - attention_mae: 0.0275\n",
            "Epoch 63: val_loss did not improve from 0.00480\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0042 - attention_mae: 0.0275 - val_loss: 0.0049 - val_attention_mae: 0.0266\n",
            "Epoch 64/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0041 - attention_mae: 0.0271\n",
            "Epoch 64: val_loss improved from 0.00480 to 0.00478, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 288ms/step - loss: 0.0041 - attention_mae: 0.0271 - val_loss: 0.0048 - val_attention_mae: 0.0250\n",
            "Epoch 65/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0041 - attention_mae: 0.0267\n",
            "Epoch 65: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0041 - attention_mae: 0.0267 - val_loss: 0.0049 - val_attention_mae: 0.0263\n",
            "Epoch 66/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0041 - attention_mae: 0.0268\n",
            "Epoch 66: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0041 - attention_mae: 0.0268 - val_loss: 0.0070 - val_attention_mae: 0.0400\n",
            "Epoch 67/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0044 - attention_mae: 0.0285\n",
            "Epoch 67: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0044 - attention_mae: 0.0285 - val_loss: 0.0098 - val_attention_mae: 0.0442\n",
            "Epoch 68/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0043 - attention_mae: 0.0282\n",
            "Epoch 68: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0043 - attention_mae: 0.0282 - val_loss: 0.0078 - val_attention_mae: 0.0443\n",
            "Epoch 69/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0041 - attention_mae: 0.0267\n",
            "Epoch 69: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0041 - attention_mae: 0.0267 - val_loss: 0.0054 - val_attention_mae: 0.0306\n",
            "Epoch 70/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0040 - attention_mae: 0.0263\n",
            "Epoch 70: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0040 - attention_mae: 0.0263 - val_loss: 0.0048 - val_attention_mae: 0.0252\n",
            "Epoch 71/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0039 - attention_mae: 0.0259\n",
            "Epoch 71: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0039 - attention_mae: 0.0259 - val_loss: 0.0051 - val_attention_mae: 0.0263\n",
            "Epoch 72/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0039 - attention_mae: 0.0261\n",
            "Epoch 72: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0039 - attention_mae: 0.0261 - val_loss: 0.0048 - val_attention_mae: 0.0270\n",
            "Epoch 73/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0039 - attention_mae: 0.0261\n",
            "Epoch 73: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0039 - attention_mae: 0.0261 - val_loss: 0.0049 - val_attention_mae: 0.0267\n",
            "Epoch 74/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0039 - attention_mae: 0.0257\n",
            "Epoch 74: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0039 - attention_mae: 0.0257 - val_loss: 0.0049 - val_attention_mae: 0.0253\n",
            "Epoch 75/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0038 - attention_mae: 0.0253\n",
            "Epoch 75: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0038 - attention_mae: 0.0253 - val_loss: 0.0048 - val_attention_mae: 0.0250\n",
            "Epoch 76/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0039 - attention_mae: 0.0258\n",
            "Epoch 76: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0039 - attention_mae: 0.0258 - val_loss: 0.0050 - val_attention_mae: 0.0250\n",
            "Epoch 77/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0039 - attention_mae: 0.0257\n",
            "Epoch 77: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0039 - attention_mae: 0.0257 - val_loss: 0.0048 - val_attention_mae: 0.0255\n",
            "Epoch 78/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0038 - attention_mae: 0.0251\n",
            "Epoch 78: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.0038 - attention_mae: 0.0251 - val_loss: 0.0052 - val_attention_mae: 0.0260\n",
            "Epoch 79/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0037 - attention_mae: 0.0250\n",
            "Epoch 79: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0037 - attention_mae: 0.0250 - val_loss: 0.0048 - val_attention_mae: 0.0254\n",
            "Epoch 80/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0038 - attention_mae: 0.0253\n",
            "Epoch 80: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.0038 - attention_mae: 0.0253 - val_loss: 0.0049 - val_attention_mae: 0.0251\n",
            "Epoch 81/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0040 - attention_mae: 0.0274\n",
            "Epoch 81: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0040 - attention_mae: 0.0274 - val_loss: 0.0054 - val_attention_mae: 0.0256\n",
            "Epoch 82/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0038 - attention_mae: 0.0259\n",
            "Epoch 82: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0038 - attention_mae: 0.0259 - val_loss: 0.0049 - val_attention_mae: 0.0255\n",
            "Epoch 83/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0038 - attention_mae: 0.0256\n",
            "Epoch 83: val_loss did not improve from 0.00478\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0038 - attention_mae: 0.0256 - val_loss: 0.0050 - val_attention_mae: 0.0283\n",
            "Epoch 84/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0036 - attention_mae: 0.0242\n",
            "Epoch 84: val_loss improved from 0.00478 to 0.00475, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 8s 283ms/step - loss: 0.0036 - attention_mae: 0.0242 - val_loss: 0.0047 - val_attention_mae: 0.0243\n",
            "Epoch 85/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0035 - attention_mae: 0.0239\n",
            "Epoch 85: val_loss did not improve from 0.00475\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0035 - attention_mae: 0.0239 - val_loss: 0.0048 - val_attention_mae: 0.0251\n",
            "Epoch 86/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0035 - attention_mae: 0.0239\n",
            "Epoch 86: val_loss improved from 0.00475 to 0.00474, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 277ms/step - loss: 0.0035 - attention_mae: 0.0239 - val_loss: 0.0047 - val_attention_mae: 0.0250\n",
            "Epoch 87/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0036 - attention_mae: 0.0241\n",
            "Epoch 87: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0036 - attention_mae: 0.0241 - val_loss: 0.0051 - val_attention_mae: 0.0272\n",
            "Epoch 88/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0036 - attention_mae: 0.0240\n",
            "Epoch 88: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0036 - attention_mae: 0.0240 - val_loss: 0.0048 - val_attention_mae: 0.0245\n",
            "Epoch 89/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0037 - attention_mae: 0.0247\n",
            "Epoch 89: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0037 - attention_mae: 0.0247 - val_loss: 0.0048 - val_attention_mae: 0.0248\n",
            "Epoch 90/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0036 - attention_mae: 0.0244\n",
            "Epoch 90: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0036 - attention_mae: 0.0244 - val_loss: 0.0049 - val_attention_mae: 0.0252\n",
            "Epoch 91/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0036 - attention_mae: 0.0248\n",
            "Epoch 91: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0036 - attention_mae: 0.0248 - val_loss: 0.0048 - val_attention_mae: 0.0239\n",
            "Epoch 92/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0036 - attention_mae: 0.0241\n",
            "Epoch 92: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0036 - attention_mae: 0.0241 - val_loss: 0.0050 - val_attention_mae: 0.0232\n",
            "Epoch 93/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0034 - attention_mae: 0.0234\n",
            "Epoch 93: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0034 - attention_mae: 0.0234 - val_loss: 0.0048 - val_attention_mae: 0.0245\n",
            "Epoch 94/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0034 - attention_mae: 0.0231\n",
            "Epoch 94: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0034 - attention_mae: 0.0231 - val_loss: 0.0048 - val_attention_mae: 0.0244\n",
            "Epoch 95/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0034 - attention_mae: 0.0233\n",
            "Epoch 95: val_loss improved from 0.00474 to 0.00474, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 273ms/step - loss: 0.0034 - attention_mae: 0.0233 - val_loss: 0.0047 - val_attention_mae: 0.0243\n",
            "Epoch 96/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0233\n",
            "Epoch 96: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0033 - attention_mae: 0.0233 - val_loss: 0.0048 - val_attention_mae: 0.0241\n",
            "Epoch 97/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0229\n",
            "Epoch 97: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0033 - attention_mae: 0.0229 - val_loss: 0.0049 - val_attention_mae: 0.0253\n",
            "Epoch 98/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0228\n",
            "Epoch 98: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0033 - attention_mae: 0.0228 - val_loss: 0.0048 - val_attention_mae: 0.0240\n",
            "Epoch 99/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0229\n",
            "Epoch 99: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0033 - attention_mae: 0.0229 - val_loss: 0.0049 - val_attention_mae: 0.0246\n",
            "Epoch 100/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0229\n",
            "Epoch 100: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0033 - attention_mae: 0.0229 - val_loss: 0.0047 - val_attention_mae: 0.0235\n",
            "Epoch 101/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0229\n",
            "Epoch 101: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0033 - attention_mae: 0.0229 - val_loss: 0.0048 - val_attention_mae: 0.0238\n",
            "Epoch 102/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0224\n",
            "Epoch 102: val_loss improved from 0.00474 to 0.00474, saving model to /content/drive/MyDrive/Research/TAVI/Models/Curvature_2_Pressure_MultiViewUNet_DO_0.5\n",
            "27/27 [==============================] - 7s 274ms/step - loss: 0.0033 - attention_mae: 0.0224 - val_loss: 0.0047 - val_attention_mae: 0.0240\n",
            "Epoch 103/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0226\n",
            "Epoch 103: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0033 - attention_mae: 0.0226 - val_loss: 0.0047 - val_attention_mae: 0.0234\n",
            "Epoch 104/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0226\n",
            "Epoch 104: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0033 - attention_mae: 0.0226 - val_loss: 0.0049 - val_attention_mae: 0.0238\n",
            "Epoch 105/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0033 - attention_mae: 0.0229\n",
            "Epoch 105: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0033 - attention_mae: 0.0229 - val_loss: 0.0049 - val_attention_mae: 0.0247\n",
            "Epoch 106/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0032 - attention_mae: 0.0223\n",
            "Epoch 106: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0032 - attention_mae: 0.0223 - val_loss: 0.0048 - val_attention_mae: 0.0238\n",
            "Epoch 107/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0031 - attention_mae: 0.0218\n",
            "Epoch 107: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0031 - attention_mae: 0.0218 - val_loss: 0.0048 - val_attention_mae: 0.0234\n",
            "Epoch 108/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0031 - attention_mae: 0.0218\n",
            "Epoch 108: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0031 - attention_mae: 0.0218 - val_loss: 0.0051 - val_attention_mae: 0.0261\n",
            "Epoch 109/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0031 - attention_mae: 0.0220\n",
            "Epoch 109: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0031 - attention_mae: 0.0220 - val_loss: 0.0048 - val_attention_mae: 0.0234\n",
            "Epoch 110/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0031 - attention_mae: 0.0217\n",
            "Epoch 110: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0031 - attention_mae: 0.0217 - val_loss: 0.0048 - val_attention_mae: 0.0232\n",
            "Epoch 111/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0032 - attention_mae: 0.0218\n",
            "Epoch 111: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0032 - attention_mae: 0.0218 - val_loss: 0.0052 - val_attention_mae: 0.0268\n",
            "Epoch 112/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0032 - attention_mae: 0.0221\n",
            "Epoch 112: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 0.0032 - attention_mae: 0.0221 - val_loss: 0.0049 - val_attention_mae: 0.0225\n",
            "Epoch 113/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0031 - attention_mae: 0.0216\n",
            "Epoch 113: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0031 - attention_mae: 0.0216 - val_loss: 0.0048 - val_attention_mae: 0.0230\n",
            "Epoch 114/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0030 - attention_mae: 0.0210\n",
            "Epoch 114: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0030 - attention_mae: 0.0210 - val_loss: 0.0048 - val_attention_mae: 0.0232\n",
            "Epoch 115/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0030 - attention_mae: 0.0209\n",
            "Epoch 115: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0030 - attention_mae: 0.0209 - val_loss: 0.0049 - val_attention_mae: 0.0226\n",
            "Epoch 116/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0030 - attention_mae: 0.0212\n",
            "Epoch 116: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0030 - attention_mae: 0.0212 - val_loss: 0.0048 - val_attention_mae: 0.0230\n",
            "Epoch 117/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0030 - attention_mae: 0.0213\n",
            "Epoch 117: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0030 - attention_mae: 0.0213 - val_loss: 0.0048 - val_attention_mae: 0.0226\n",
            "Epoch 118/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0030 - attention_mae: 0.0214\n",
            "Epoch 118: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0030 - attention_mae: 0.0214 - val_loss: 0.0049 - val_attention_mae: 0.0228\n",
            "Epoch 119/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0031 - attention_mae: 0.0219\n",
            "Epoch 119: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.0031 - attention_mae: 0.0219 - val_loss: 0.0048 - val_attention_mae: 0.0231\n",
            "Epoch 120/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0030 - attention_mae: 0.0213\n",
            "Epoch 120: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0030 - attention_mae: 0.0213 - val_loss: 0.0050 - val_attention_mae: 0.0228\n",
            "Epoch 121/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0029 - attention_mae: 0.0212\n",
            "Epoch 121: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0029 - attention_mae: 0.0212 - val_loss: 0.0049 - val_attention_mae: 0.0239\n",
            "Epoch 122/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0030 - attention_mae: 0.0214\n",
            "Epoch 122: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 248ms/step - loss: 0.0030 - attention_mae: 0.0214 - val_loss: 0.0049 - val_attention_mae: 0.0231\n",
            "Epoch 123/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0029 - attention_mae: 0.0211\n",
            "Epoch 123: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0029 - attention_mae: 0.0211 - val_loss: 0.0049 - val_attention_mae: 0.0226\n",
            "Epoch 124/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0029 - attention_mae: 0.0208\n",
            "Epoch 124: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0029 - attention_mae: 0.0208 - val_loss: 0.0049 - val_attention_mae: 0.0230\n",
            "Epoch 125/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0029 - attention_mae: 0.0205\n",
            "Epoch 125: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0029 - attention_mae: 0.0205 - val_loss: 0.0050 - val_attention_mae: 0.0237\n",
            "Epoch 126/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0029 - attention_mae: 0.0206\n",
            "Epoch 126: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0029 - attention_mae: 0.0206 - val_loss: 0.0048 - val_attention_mae: 0.0231\n",
            "Epoch 127/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0029 - attention_mae: 0.0208\n",
            "Epoch 127: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0029 - attention_mae: 0.0208 - val_loss: 0.0048 - val_attention_mae: 0.0227\n",
            "Epoch 128/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0029 - attention_mae: 0.0213\n",
            "Epoch 128: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 249ms/step - loss: 0.0029 - attention_mae: 0.0213 - val_loss: 0.0049 - val_attention_mae: 0.0242\n",
            "Epoch 129/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0030 - attention_mae: 0.0220\n",
            "Epoch 129: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0030 - attention_mae: 0.0220 - val_loss: 0.0049 - val_attention_mae: 0.0231\n",
            "Epoch 130/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0028 - attention_mae: 0.0204\n",
            "Epoch 130: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 250ms/step - loss: 0.0028 - attention_mae: 0.0204 - val_loss: 0.0049 - val_attention_mae: 0.0232\n",
            "Epoch 131/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0028 - attention_mae: 0.0202\n",
            "Epoch 131: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.0028 - attention_mae: 0.0202 - val_loss: 0.0048 - val_attention_mae: 0.0221\n",
            "Epoch 132/300\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0027 - attention_mae: 0.0200\n",
            "Epoch 132: val_loss did not improve from 0.00474\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.0027 - attention_mae: 0.0200 - val_loss: 0.0048 - val_attention_mae: 0.0224\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_batches,\n",
        "    validation_data=test_batches,\n",
        "    epochs=N_EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYJgw9qhh7ew"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bux6go2yh7ew"
      },
      "outputs": [],
      "source": [
        "timestamp = datetime.datetime.now().strftime(\"%b-%d-%I:%M%p\")\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)\n",
        "\n",
        "model.save(os.path.join(model_path, timestamp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMFZgyu9h7ex"
      },
      "source": [
        "# Save Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnsfVhkDh7ex",
        "outputId": "cac4f3c6-9ffd-47b5-e2af-fdd10cbbce49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 983ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r1it [00:01,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:01,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:01,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:01,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [00:01,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [00:01,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [00:02,  6.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [00:02,  7.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [00:02,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [00:02,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [00:02,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [00:02,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [00:02,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [00:02,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [00:03,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [00:03,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r18it [00:03,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [00:03,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [00:03,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [00:03,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r22it [00:03,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r23it [00:03,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r24it [00:03,  8.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r25it [00:04,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [00:04,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [00:04,  7.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r28it [00:04,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r29it [00:04,  6.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r30it [00:04,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r31it [00:04,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r32it [00:05,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r33it [00:05,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r34it [00:05,  7.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r35it [00:05,  7.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r36it [00:05,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r37it [00:05,  7.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r38it [00:05,  7.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r39it [00:06,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r40it [00:06,  6.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r41it [00:06,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r42it [00:06,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r43it [00:06,  7.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r44it [00:06,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r45it [00:06,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r46it [00:07,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 85ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r47it [00:07,  6.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r48it [00:07,  6.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r49it [00:07,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r50it [00:07,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r51it [00:07,  5.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r52it [00:08,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r53it [00:08,  6.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r54it [00:08,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r55it [00:08,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r56it [00:08,  5.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r57it [00:09,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r58it [00:09,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r59it [00:09,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r60it [00:09,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r61it [00:09,  6.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r62it [00:09,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r63it [00:10,  6.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r64it [00:10,  6.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r65it [00:10,  6.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r66it [00:10,  6.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r67it [00:10,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r68it [00:10,  6.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r69it [00:10,  6.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r70it [00:11,  7.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r71it [00:11,  7.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r72it [00:11,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r73it [00:11,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r74it [00:11,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r75it [00:11,  8.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r76it [00:11,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r77it [00:11,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r78it [00:11,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r79it [00:12,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r80it [00:12,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r81it [00:12,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r82it [00:12,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r83it [00:12,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r84it [00:12,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r85it [00:12,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r86it [00:12,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r87it [00:12,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r88it [00:13,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r89it [00:13,  8.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r90it [00:13,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r91it [00:13,  8.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r92it [00:13,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r93it [00:13,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r94it [00:13,  9.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r95it [00:13,  9.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [00:14,  6.85it/s]\n"
          ]
        }
      ],
      "source": [
        "test_ds_unbatched = test_batches.unbatch()\n",
        "\n",
        "pred_path = os.path.join(PRED_PATH, EXP_NAME, timestamp)\n",
        "if not os.path.exists(pred_path):\n",
        "    os.makedirs(pred_path)\n",
        "\n",
        "metrics = pd.DataFrame()\n",
        "\n",
        "for idx, (input, target) in enumerate(tqdm(test_ds_unbatched)):\n",
        "    target = tf.squeeze(target)\n",
        "    prediction = tf.squeeze(model.predict(tf.expand_dims(input, axis=0)))\n",
        "\n",
        "    channel_sum = tf.expand_dims(tf.reduce_sum(target, axis=-1), axis=-1)\n",
        "    white_mask = tf.reduce_all(tf.equal(channel_sum, 3.0), axis=-1)\n",
        "    expanded_mask = tf.expand_dims(white_mask, axis=-1)\n",
        "    expanded_mask = tf.tile(expanded_mask, [1, 1, 3])\n",
        "    prediction = tf.where(expanded_mask, tf.ones_like(prediction), prediction)\n",
        "\n",
        "    target_pil = Image.fromarray(np.array(target * 255.0, dtype=np.uint8))\n",
        "    prediction_pil = Image.fromarray(\n",
        "        np.array(prediction * 255.0, dtype=np.uint8))\n",
        "\n",
        "    target_pil.save(os.path.join(pred_path, f\"{idx}_T.png\"))\n",
        "    prediction_pil.save(os.path.join(pred_path, f\"{idx}_P.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Predictions - CycleGAN Compatible"
      ],
      "metadata": {
        "id": "qRpWQsg8e80y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_path = os.path.join(PRED_PATH, EXP_NAME, \"CG_\" + timestamp)\n",
        "if not os.path.exists(pred_path):\n",
        "    os.makedirs(pred_path)\n",
        "\n",
        "test_input_path = os.path.join(DATASET_PATH, TEST_DIR, INPUT_DIR)\n",
        "for test_input in os.listdir(test_input_path):\n",
        "\n",
        "    test_target_path = os.path.join(DATASET_PATH, TEST_DIR, TARGET_DIR)\n",
        "\n",
        "    test_input_img = tf.keras.utils.load_img(\n",
        "        path=os.path.join(test_input_path, test_input),\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        interpolation=\"bilinear\",\n",
        "        keep_aspect_ratio=False\n",
        "    )\n",
        "\n",
        "    test_target_img = tf.keras.utils.load_img(\n",
        "        path=os.path.join(test_target_path, test_input),\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        interpolation=\"bilinear\",\n",
        "        keep_aspect_ratio=False\n",
        "    )\n",
        "\n",
        "    input_arr = tf.keras.utils.img_to_array(test_input_img)\n",
        "    input_arr = normalization_layer(np.array([input_arr]))\n",
        "\n",
        "    target_arr = tf.keras.utils.img_to_array(test_target_img)\n",
        "    target_arr = normalization_layer(target_arr)\n",
        "\n",
        "    prediction = tf.squeeze(model.predict(input_arr))\n",
        "\n",
        "    channel_sum = tf.expand_dims(tf.reduce_sum(target_arr, axis=-1), axis=-1)\n",
        "    white_mask = tf.reduce_all(tf.equal(channel_sum, 3.0), axis=-1)\n",
        "    expanded_mask = tf.expand_dims(white_mask, axis=-1)\n",
        "    expanded_mask = tf.tile(expanded_mask, [1, 1, 3])\n",
        "    prediction = tf.where(expanded_mask, tf.ones_like(prediction), prediction)\n",
        "\n",
        "    target_pil = test_target_img\n",
        "    prediction_pil = Image.fromarray(\n",
        "        np.array(prediction * 255.0, dtype=np.uint8))\n",
        "\n",
        "    base_name = test_input.replace(\".png\", \"\")\n",
        "    target_name = base_name + \"_target.png\"\n",
        "    prediction_name = base_name + \"_fake.png\"\n",
        "\n",
        "    target_pil.save(os.path.join(pred_path, target_name))\n",
        "    prediction_pil.save(os.path.join(pred_path, prediction_name))\n"
      ],
      "metadata": {
        "id": "SzjTo6vne8iE",
        "outputId": "c17e53f8-b678-4501-be28-cae465441ebf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHrb18xrh7ex"
      },
      "source": [
        "# Loss Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "27vxXlXEh7ex",
        "outputId": "a68e8f24-2458-49be-c1df-8a541799cbef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "try:\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.ylabel('Attention MAE')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(model_path, timestamp + \".png\"))\n",
        "    plt.show()\n",
        "except:\n",
        "    print(\"Model did not finish training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McOnJlPwh7ex"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kbXsKlmh7e0",
        "outputId": "ce7110c4-64cc-4d57-d563-a96d639c57a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0047 - attention_mae: 0.0240\n",
            "EMSE: 0.004737428855150938\n",
            "EMAE: 0.02398441918194294\n"
          ]
        }
      ],
      "source": [
        "EMSE, EMAE = model.evaluate(test_batches)\n",
        "print(f\"EMSE: {EMSE}\\nEMAE: {EMAE}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}